---
title: "Vignette for the DOS Proportion Estimator"
output:
   rmarkdown::html_vignette:
    toc: true
    number_sections: true
header-includes:
- |
  ```{=latex}
   \usepackage{amsmath}
   \usepackage{calc}
   \usepackage{accents}
   \newcommand{\dbtilde}[1]{\accentset{\approx}{#1}}
   ```

vignette: >
  %\VignetteIndexEntry{dos-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, echo = FALSE}
library(MTCP)
```

This vignette offers access to the source code used for simulations, plots, and tables in the main paper. 

# DOS-Storey Illustrations 

The following code produces plots illustrating the DOS method.

Parameters in the dense case:

```{r illustration_set1, eval = FALSE}
set.seed(2)
n <- 100
mu <- 2
eps <- 0.2
```

Parameters in the sparse case:

```{r illustration_set2, eval = FALSE}
set.seed(1)
n <- 100
mu <- 3
eps <- 0.05
```

Plotting Storey's estimator as a function of $\lambda$:

```{r Storeys_sequence, eval = FALSE}
p_seq <- sim_pval(n, 0, mu, eps, 0)
k <- eps * n
pch_type <- c(rep(4, k), rep(20, n - k))
ord <- order(p_seq)
col <- c(rep("red", k), rep("black", n - k))
col <- col[ord]
pch_type <- pch_type[ord]
p_seq <- sort(p_seq)

plot(storey_pi1est(p_seq, p_seq)$est, xlab = expression(lambda), ylab = "", pch = 20)
title(ylab = expression(hat(pi)[1](lambda)), line = 2.5)
abline(h = eps)
```

The following code produces:

 * The plot of p-values with the corresponding DOS sequence.
 * The plot of Storey's sequence of estimators with a vertical line indicating the DOS estimate value.

```{r illustration1, eval = FALSE }
p_seq <- sim_pval(n, 0, mu, eps, 0)
k <- n * eps
pch_type <- c(rep(4, k), rep(20, n - k))
ord <- order(p_seq)
col <- c(rep("red", k), rep("black", n - k))
col <- col[ord]
pch_type <- pch_type[ord]
p_seq <- sort(p_seq)

par(mar = c(5, 4, 4, 4) + 0.1)

plot(p_seq[1:(n/2)], axes = FALSE, ylab = "", xlab = "i", pch = pch_type, col = col)
axis(2, ylim = c(0, 1), col = "black", las = 1)
mtext(expression(p[(i)]), side = 2, line = 2.5)
box()
par(new = TRUE)

plot(c(dos_fun(p_seq)$dos_seq, rep(0, n/2)), xlab = "", ylab = "", ylim = range(dos_fun(p_seq)$dos_seq),
     axes = FALSE, type = "l")
mtext(expression(d[1](i)), side = 4, line = 2.5)
axis(4, ylim = range(dos_fun(p_seq, 1)$dos_seq), las = 1)
axis(1)
legend("bottomright", legend = c(expression(H[1]), expression(H[0]), "DOS"), col = c("red", "black", "black"), pch = c(4, 20, 30), lty = c(0, 0, 1), cex = 0.8)
abline(v = which.max(dos_fun(p_seq)$dos_seq), lty = "dashed")

plot(storey_pi1est(p_seq, p_seq)$est, xlab = "i", ylab = "", pch = 20)
title(ylab = expression(hat(pi)[1](p[(i)])), line = 2.5)
abline(h = eps)
abline(v = which.max(dos_fun(p_seq)$dos_seq), lty = "dashed")

```

The following code generates a plot of p-values along with the corresponding piecewise linear function, fitted using the DOS method.

```{r fitting a line, eval = FALSE}
cp_loc <- dos_fun(p_seq)$cp_loc
pch_type <- c(rep(4, k), rep(20, n - k))
pch_type <- pch_type[ord]

plot(p_seq, pch = pch_type, col = col, ylab = "p-value", xlab = "Rank")

lines((1:cp_loc) * (p_seq[cp_loc]) / cp_loc, col = "blue", lwd = 2)
lines(cp_loc:n, (cp_loc:n - cp_loc) * (1 - p_seq[cp_loc]) / (n - cp_loc) + p_seq[cp_loc], col = "blue", lwd = 2)

legend("bottomright", legend = c(expression(H[1]), expression(H[0])), col = c("red", "black"), pch = c(4, 20), cex = 0.8)

```

This code generates a plot of spacings of p-values along with the corresponding piece-wise constant function, fitted using the DOS method.

```{r fitting spacings, eval = FALSE}
cp_loc <- dos_fun(p_seq)$cp_loc
col_spac <- rep(0, n - 1)

for (i in 1:(n - 1)) {
  if (col[i] == col[i + 1])
    col_spac[i] <- col[i]
  else
    col_spac[i] <- "darkred"
}

pch_type <- car::recode(col_spac, "'black' = 20; 'darkred' = 15; 'red' = 18;")

last_red <- max(which(col == "red"))
# col_spac <- c(rep("red", last_red - 1), rep("black", n - last_red))

plot(diff(p_seq), pch = pch_type, col = col_spac, ylab = "Spacing")
lines(c(rep(mean(diff(p_seq[1:cp_loc])), cp_loc), rep(mean(diff(p_seq[-(1:cp_loc)])), n - cp_loc)), col = "blue", lwd = 2)

legend("topleft", legend = c(expression(H[1]), expression(H[1] ~ "&" ~ H[0]), expression(H[0])), col = c("red", "darkred", "black"), pch = c(18, 15, 20), cex = 0.8)

```


# DOS Simulations 

## DOS-Storey for Proportion Estimation Under Uniformity and Independence

The code in this section compares the DOS method to different methods for estimating the false null proportion in terms of the estimators' bias, standard deviation, and the Root Mean Squared Error (RMSE). The methods used for comparison are:

* **BH09** - From Cai, T. T., Sun, W., & Xia, Y. (2022). LAWS: A Locally Adaptive Weighting and Screening Approach to Spatial Multiple Testing. Journal of the American Statistical Association, 117(539), 1370–1383. https://doi.org/10.1080/01621459.2020.1859379
* **BOOTSTRAP** - Storey, J. D., Taylor, J. E., & Siegmund, D. (2004). Strong control, conservative point estimation and simultaneous conservative consistency of false discovery rates: a unified approach. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 66(1), 187–205.  https://doi.org/10.1111/j.1467-9868.2004.00439.x 
* **FIX05** - Storey's estimator of the false null proportion with $\lambda=0.5$
* **FIXMED** - Storey's estimator of the false null proportion with $\lambda=p_{(n/2)}$, where $\lambda=p_{(n/2)}$ is the median of the $p$-values sequence
* **JD** - Jiang, H., & Doerge, R. W. (2008). Estimating the Proportion of True Null Hypotheses for Multiple Comparisons. Cancer Informatics, 6, 117693510800600. https://doi.org/10.1177/117693510800600001
* **LLF_CONVEST** and **LLF_GRENANDER** - Langaas, M., Lindqvist, B. H., & Ferkingstad, E. (2005). Estimating the Proportion of True Null Hypotheses, with Application to DNA Microarray Data. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 67(4), 555–572 https://doi.org/10.1111/j.1467-9868.2005.00515.x 
* **LSL** - Benjamini, Y., & Hochberg, Y. (2000). On the Adaptive Control of the False Discovery Rate in Multiple Testing with Independent Statistics. Journal of Educational and Behavioral Statistics, 25(1), 60. https://doi.org/10.2307/1165312
* **MGF** & **PRE** - Broberg, P. (2005). A comparative review of estimates of the proportion unchanged genes and the false discovery rate. BMC Bioinformatics, 6, 199. https://doi.org/10.1186/1471-2105-6-199 
* **MR** - Meinshausen, N., & Rice, J. (2006). Estimating the proportion of false null hypotheses among a large number of independently tested hypotheses. Annals of Statistics, 34(1), 373–393. https://doi.org/10.1214/009053605000000741 
* **STS** - Storey, J. D., & Tibshirani, R. (2003). Statistical significance for genomewide studies. Proceedings of the National Academy of Sciences, 100(16), 9440–9445. https://doi.org/10.1073/pnas.1530509100 

The following R packages are required to compute some of the methods mentioned above and produce a LaTeX table:

```{r dependencies, eval = FALSE}
if (!requireNamespace("fdrtool", quietly = TRUE)) {
    install.packages("fdrtool", quietly = TRUE)
  }
if (!requireNamespace("qvalue", quietly = TRUE)) {
  BiocManager::install("qvalue")
}
if (!requireNamespace("limma", quietly = TRUE)) {
  BiocManager::install("limma")
}
if (!requireNamespace("xtable", quietly = TRUE)) {
  BiocManager::install("xtable")
}

library("fdrtool")
library("qvalue")
library("limma")
library("xtable")
```

The following function generates a table that reports the bias, standard deviation, and Root Mean Squared Error (RMSE) of different proportion estimators.

```{r complete testing function, eval = FALSE}
dos_test_gaussian <- function(n, eps, mu, N) {
  mat <- matrix(0, N, 14)
  colnames(mat) <- c("DOS1", "DOS05", "BH09", "BOOTSTRAP", "FIX05", "FIXMED",
                     "JD", "LLF_CONVEST", "LLF_GRENANDER", "LSL", "MGF", "MR",
                     "PRE", "STS")
  df <- data.frame(mat)

  for (i in 1:N) {
    p_seq <- sort(sim_pval(n, 0, mu, eps, 0))
    
    df$DOS1[i] <- storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1)$cp_loc], p_seq)$est
    df$DOS05[i] <- storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1/2)$cp_loc], p_seq)$est
    df$BH09[i] <- storey_pi1est(max(which(sort(p_seq) <= 0.9 * (1:n) / n)) / n, p_seq)$est
    df$FIX05[i] <- storey_pi1est(0.5, p_seq)$est
    df$FIXMED[i] <- storey_pi1est(p_seq[n/2], p_seq)$est
    df$BOOTSTRAP[i] <- 1 - qvalue::pi0est(p_seq, pi0.method = "bootstrap")$pi0
    df$STS[i] <- 1 - qvalue::pi0est(p_seq, pi0.method = "smoother")$pi0
    df$LSL[i] <- 1 - fdrtool::pval.estimate.eta0(p_seq, method = "adaptive", diagnostic.plot = FALSE)
    df$PRE[i] <- 1 - PRE_est(p_seq)
    df$MGF[i] <- 1 - MGF_est(p_seq)
    df$JD[i] <- 1 - min(1, JD_est(p_seq, 1000))
    df$LLF_GRENANDER[i] <- 1 - LLF_Grenander_est(p_seq)
    df$LLF_CONVEST[i] <- 1 - limma::convest(p_seq)
    df$MR[i] <- MR_est(p_seq)
  }
  
  res <- rbind(apply(df, MARGIN = 2, FUN = mean), apply(df, MARGIN = 2, FUN = sd))
  res[1, ] <- res[1, ] - eps
  res <- rbind(res, sqrt(res[1, ]^2 + res[2, ]^2))
  rownames(res) <- c("BIAS", "SD", "RMSE")
  
  return(res)
}
```

The following code produces a latex table of the simulation results obtained using the function `dos_test_gaussian` for sample of size $n=1000$ for various $\mu$ and $\varepsilon$ values and the simulations are based on $N=1000$ repetitions. 

Note: The number of bootstrap samples used in the main paper for JD method is 1000, which significantly slowes down the computation time. If running the simulation study below, we recommend using smaller numbers.

```{r simulations, eval=FALSE}
set.seed(10)
N <- 1000
n_seq <- rep(1000, 8)
eps_seq <- c(0.01, 0.03, 0.05, 0.1, 0.1, 0.2, 0.2, 0.3)
mu_seq <- c(3.5, 3.5, 3, 2, 3, 2, 3, 3)

table_list <- list()
for (i in 1:length(n_seq)) {
  table_list[[i]] <- round(dos_test_gaussian(n_seq[i], eps_seq[i],
                                             mu_seq[i], N) * n_seq[i], 1)
  rownames(table_list[[i]]) <- NULL
}

combined_table <- do.call(rbind, table_list)
row_names <- as.data.frame(rep(c("BIAS", "SD", "RMSE"), length(n_seq)))
colnames(row_names) <- ""
combined_table <- cbind(row_names, combined_table)

add_rows <- list()
add_rows$pos <- as.list(3 * (1:length(n_seq) - 1))
mu_info <- paste("mu =", mu_seq)
eps_info <- paste("eps =", eps_seq)
add_rows$command <- paste("\\hline\n", "\\multicolumn{14}{c}{",
                          mu_info, ",", eps_info, "} \\\\\\hline ")
print(xtable(combined_table), add.to.row = add_rows, include.rownames = FALSE)

```

Similarly to  `dos_test_gaussian` the following function generates a table that reports the bias, standard deviation, and Root Mean Squared Error (RMSE) of different proportion estimators. Some of the methods used in `dos_test_gaussian` do not work for smaller sample values and are excluded.

```{r small sample testing function, eval = FALSE}
dos_test_gaussian_small=function(n,eps,mu,N)
{
  mat <- matrix(0, N, 10)
  colnames(mat)=c("DOS1", "DOS05", "BH09", "FIX05", "FIXMED", "JD", "LLF_CONVEST",
                   "LSL", "MGF", "MR")
  
  df <- data.frame(mat)

  for (i in 1:N) {
    p_seq <- sort(sim_pval(n, 0, mu, eps, 0))
    
    df$DOS1[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1)$cp_loc], p_seq)$est
    df$DOS05[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1/2)$cp_loc], p_seq)$est

    df$BH09[i] <- storey_pi1est(max(which(sort(p_seq) <= 0.9*(1:n)/n))/n, p_seq)$est
    df$FIX05[i] <- storey_pi1est(0.5, p_seq)$est
    df$FIXMED[i] <- storey_pi1est(p_seq[n/2], p_seq)$est
    df$LSL[i] <- 1 - fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                 diagnostic.plot = FALSE)
    df$MGF[i] <- 1 - MGF_est(p_seq)
    df$JD[i] <- 1 - min(1, JD_est(p_seq, 100))
    df$LLF_CONVEST[i] <- 1 - limma::convest(p_seq)
    df$MR[i] <- MR_est(p_seq)
  }
  
  res <- rbind(apply(df, MARGIN = 2, FUN = mean),
               apply(df, MARGIN = 2, FUN = sd))
  res[1, ] <- res[1, ] - eps
  res <- rbind(res, sqrt(res[1, ]^2 + res[2, ]^2))
  rownames(res) <- c("BIAS", "SD", "RMSE")
  boxplot(df, ylab = expression(hat(pi)[1]))
  abline(h = eps)
  
  return((res))
}
```

The following code produces a latex table of simulation results for different small sample sizes $n$ and for various $\mu$ and $\varepsilon$ values. The simulations are based on $N=1000$ repetitions.

```{r small sample simulations, eval = FALSE}
N = 1000
n_seq=c(50,50,50,100,100,100,100)
eps_seq=c(0.1,0.2,0.4,0.05,0.1,0.2,0.4)
mu_seq=c(3,2,2,3,3,2,2)
set.seed(20)

table_list <- list()
for (i in 1:length(n_seq)) {
  table_list[[i]] <- round(dos_test_gaussian_small(n_seq[i], eps_seq[i],
                                             mu_seq[i], N) * n_seq[i], 1)
  rownames(table_list[[i]]) <- NULL
}

combined_table <- do.call(rbind, table_list)
row_names <- as.data.frame(rep(c("BIAS", "SD", "RMSE"), length(n_seq)))
colnames(row_names) <- ""
combined_table <- cbind(row_names, combined_table)

add_rows <- list()
add_rows$pos <- as.list(3 * (1:length(n_seq) - 1))
mu_info <- paste("mu =", mu_seq)
eps_info <- paste("eps =", eps_seq)
add_rows$command <- paste("\\hline\n", "\\multicolumn{10}{c}{",
                          mu_info, ",", eps_info, "} \\\\\\hline ")
print(xtable(combined_table), add.to.row = add_rows, include.rownames = FALSE)
```

## uDOS Proportion Estimator When True Null p-values are Superuniform

When the $p$-values are superuniform, we modify the DOS false null proportion estimator and use the change-point estimator as the estimator for the number of the false null $p$-values. This method is called uDOS in the main paper and we compare it with the method
based on the randomised p-values by Hoang, A.-T., & Dickhaus, T. (2022). On the usage of randomized p-values in the Schweder–Spjøtvoll estimator. Annals of the Institute of Statistical Mathematics, 74(2), 289–319.
 https://doi.org/10.1007/s10463-021-00797-0and. The simulation setting is as described in that paper.

```{r superuniform, eval = FALSE}
#set.seed(005) #for pi1 = 0.05
#set.seed(025) #for pi1 = 0.25
r <- 1:10
pi1 <- 0.25
rho <- 0.75
n <- 100
N <- 10000
dos1_cp_est <- rep(0, N)
dos12_cp_est <- rep(0, N)
hd_est_seq <- rep(0, N)
storey12_est <- rep(0, N)
max_spac_est <- rep(0, N)

arr <- array(
  data = rep(0, 3 * 4 * length(r)),
  dim = c(3, 4, length(r)),
  dimnames = list(
    c("BIAS", "SD", "MSE"),
    c("DOS-1", "DOS-1/2", "HD", "ST-1/2"),
    1:length(r)
  )
)

for (i in 1:length(r)) {
  for (j in 1:N) {
    p_seq <- sort(sim_pval(n, -0.2 * r[i], 1 + 0.25 * r[i], pi1, rho))
    dos1_cp_est[j] <- dos_fun(p_seq)$cp_loc / n
    dos12_cp_est[j] <- dos_fun(p_seq, 1/2)$cp_loc / n
    hd_est_seq[j] <- hd_est(p_seq)$pi1_est
    storey12_est[j] <- storey_pi1est(0.5, p_seq)$est
  }
  
  arr["BIAS", "DOS-1", i] <- mean(dos1_cp_est) - pi1
  arr["BIAS", "DOS-1/2", i] <- mean(dos12_cp_est) - pi1
  arr["BIAS", "HD", i] <- mean(hd_est_seq) - pi1
  arr["BIAS", "ST-1/2", i] <- mean(storey12_est) - pi1
  
  arr["SD", "DOS-1", i] <- sd(dos1_cp_est)
  arr["SD", "DOS-1/2", i] <- sd(dos12_cp_est)
  arr["SD", "HD", i] <- sd(hd_est_seq)
  arr["SD", "ST-1/2", i] <- sd(storey12_est)
  
  arr["MSE", , i] <- arr["SD", , i]^2 + arr["BIAS", , i]^2
}

par(mar = c(4, 4, 2, 1)) 

mat <- t(arr["BIAS", 1:3, ])
matplot(mat + pi1, type = "b", xlab = "", ylab = "", pch = 1:3, ylim = c(0, 2 * pi1))
title(xlab = "r", line = 2.3, cex.lab = 1.2)
title(ylab = "MEAN", line = 2.3, cex.lab = 1)
abline(h = pi1)
legend("topright", colnames(mat), col = seq_len(ncol(mat)), pch = 1:3, cex = 0.9)

mat <- t(arr["SD", 1:3, ])
matplot(mat, type = "b", pch = 1:3, ylab = "", xlab = "")
title(xlab = "r", line = 2.3, cex.lab = 1.2)
title(ylab = "SD", line = 2.3, cex.lab = 1)
legend("topright", colnames(mat), col = seq_len(ncol(mat)), pch = 1:3, cex = 0.9)

mat <- t(arr["MSE", 1:3, ])
matplot(mat, type = "b", pch = 1:3, xlab = "", ylab = "")
title(xlab = "r", line = 2.3, cex.lab = 1.2)
title(ylab = "MSE", line = 2.3, cex.lab = 1)
legend("topright", colnames(mat), col = seq_len(ncol(mat)), pch = 1:3, cex = 0.9)

```


# Real Data Example


Necessary packages 

```{r example packages, echo = TRUE, results = 'hide'}
packages <- c("devtools", "dplyr", "neuroblastoma")
#install.packages(packages)
#devtools::install_github("jewellsean/ChangepointInference")
lapply(c(packages, "ChangepointInference"), library, character.only = TRUE)
```

Loading the data 

```{r loading data, eval = FALSE}
data(neuroblastoma)
nb_data <- neuroblastoma$profiles
nb_an <- neuroblastoma$annotations

chr_no <- c(1, 2, 3, 4, 11, 17)

chr_an <- vector("list", length(chr_no))
s <- vector("list", length(chr_no))
e <- vector("list", length(chr_no))
chr_data <- vector("list", length(chr_no))
profiles_chr <- vector("list", length(chr_no))

for (i in 1:length(chr_no)) {
  temp_an <- filter(nb_an, chromosome == chr_no[i]) %>%
    arrange(profile.id)

  s[[i]] <- temp_an$min[1]
  e[[i]] <- temp_an$max[1]

  temp_an <- select(temp_an, -(chromosome:max))
  chr_an[[i]] <- temp_an

  temp_data <- filter(nb_data, chromosome == chr_no[i]) %>%
    arrange(profile.id) %>%
    select(-chromosome)

  chr_data[[i]] <- temp_data

  profiles_chr[[i]] <- unique(temp_an$profile.id)
}
```

Plot a specific profile:

```{r plot profile, eval = FALSE}
chr_no <- c(1, 2, 3, 4, 11, 17)
i <- 1
j <- 7
#chr_an[[i]][j,] # annotation for the given profile

dat <- chr_data[[i]] %>%
  filter(profile.id == profiles_chr[[i]][j]) %>%
  filter(position >= s[[i]] & position <= e[[i]])

dat %>%
  with(plot(logratio))
```

Plot multiple profiles on one plot, for a given chromosome

```{r multiple profiles, eval = FALSE}
i <- 1
annots <- an_list[[i]][1:10]
pat_col <- ifelse(annots == 0, 'black', 'red')

pat_dat <- chr_data[[i]] %>%
  filter(profile.id == profiles_chr[[i]][1])

plot(
  pat_dat[, 3] + 1,
  type = "l",
  ylim = c(0.5, 10.5),
  xlab = "probes",
  ylab = "patient number"
)

for (j in 2:10) {
  pat_dat <- chr_data[[i]] %>%
    filter(profile.id == profiles_chr[[i]][j])

  lines(pat_dat[, 3] + j, pch = 20)
}

for (j in 1:10) {
  pat_dat <- chr_data[[i]] %>%
    filter(profile.id == profiles_chr[[i]][j])

  lines(
    which(pat_dat$position >= s[[i]] & pat_dat$position <= e[[i]]),
    pat_dat[pat_dat$position >= s[[i]] & pat_dat$position <= e[[i]], 3] + j,
    col = pat_col[j],
    pch = 20
  )
}

abline(h = 0:10, lty = 2)

```

Get all the annotations in a list

```{r annot list, eval = FALSE}
an_list <- vector("list", length(chr_no))

for (i in 1:length(chr_no)) {
  an_list[[i]] <- chr_an[[i]] %>%
    select(annotation) %>%
    mutate(annotation = recode(annotation, 'breakpoint' = 1, 'normal' = 0)) %>%
    unlist() %>%
    as.numeric()
}
```

Get the $p$-value

```{r get pvals, eval = FALSE}
K <- 1
h <- 5
q <- 0.025

p_seq <- vector("list", length(chr_no))

pb <- txtProgressBar(max = length(chr_no))

for (i in 1:length(chr_no)) {
  
  for (j in 1:length(profiles_chr[[i]])) {
    dat <- chr_data[[i]] %>%
      filter(profile.id == profiles_chr[[i]][j]) %>%
      filter(position >= s[[i]] & position <= e[[i]])
    
    dat_seq <- dat$logratio
    dat_seq <- dat_seq[dat_seq > quantile(dat_seq, q) &
                       dat_seq < quantile(dat_seq, 1 - q)]
    
    fit_inference <- changepoint_inference(dat_seq, 'BS-fixed', K, window_size = h)
    p_seq[[i]][j] <- fit_inference$pvals
  }
  
  setTxtProgressBar(pb, i)
}

close(pb)
```

Plot the $p$-values

```{r pval plot, eval = FALSE}
for (i in 1:length(chr_no)) {
  ord_pseq <- order(p_seq[[i]])
  col <- an_list[[i]] 
  col <- car::recode(col, "0='lightgrey'; 1 = 'black'")
  plot(p_seq[[i]][ord_pseq], col =  col[ord_pseq], lwd = 2, ylab = "", main = paste("Chromosome", chr_no[i]), type = "h")
}
```

Calculate the number of profiles with changes:

```{r estimate cnv prop, eval = FALSE}
estimates <- vector("list", length(chr_no))

for (i in 1:length(chr_no)) {
  p_temp <- sort(p_seq[[i]])
  cp_loc <- dos_fun(p_temp)$cp_loc

  dos_est <- round(storey_pi1est(p_temp[cp_loc], p_temp)$est * length(p_temp))
  st05_est <- storey_pi1est(0.5, p_temp)$est * length(p_temp)
  an_est <- sum(an_list[[i]])

  estimates[[i]] <- data.frame("DOS" = dos_est, "ST05" = st05_est, "ANNOT" = an_est)
}

estimates
```


Estimate the subset of profiles with changes in the copy number values for each chromosome using the adaptive BH procedure, with FDR level set at $\alpha = 0.05$.

```{r cnv bh est, eval = FALSE}

alpha = 0.05

BH_estimates <- vector("list", length(chr_no))
BH_estimates <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(BH_estimates) <- c("DOS","ST-1/2", "DOS fdr", "DOS power", "ST fdr", "ST power","ANNOT")

for (i in 1:length(chr_no)) {
  
  temp_p <- p_seq[[i]]
  n <- length(p_seq[[i]])
  
  for(j in 1:2) {
    
    pi0 <- as.numeric(1- estimates[[i]][j]/n)
    
    bh_res <- bh_adaptive(temp_p, pi0, alpha, an_list[[i]])
    BH_estimates[i,j] <-  bh_res$est
    
    BH_estimates[i, j*2 + 1] <- bh_res$fdr
    BH_estimates[i, j*2 + 2] <- bh_res$power
    
    
    
  }
  
  an_est <- sum(an_list[[i]])
  BH_estimates[i,7] <- an_est
  
}

BH_estimates

```


# Additional Simulations
## Simulations Under Dependency 

The following plot illustrates $p$-values under dependence

```{r dependent_pvals, eval = FALSE}

n <- 1000; mu <- 3; eps = 0.1; rho = 0.2
p_seq <- sort(sim_pval(n, 0, mu, eps, rho))
plot(p_seq, type = "l")

```

The following function performs simulation under dependence.

```{r sim_depend, eval = FALSE}

dos_test_gaussian_depend=function(n,eps,mu,N, rho)
{
  mat <- matrix(0, N, 9)
  colnames(mat)=c("DOS1", "DOS05", "FIX05", "FIXMED", "JD", "LLF_CONVEST",
                   "LSL", "MGF", "MR")
  
  df <- data.frame(mat)

  for (i in 1:N) {
    p_seq <- sort(sim_pval(n, 0, mu, eps, rho))
    
    df$DOS1[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1)$cp_loc], p_seq)$est
    df$DOS05[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1/2)$cp_loc], p_seq)$est

    df$FIX05[i] <- storey_pi1est(0.5, p_seq)$est
    df$FIXMED[i] <- storey_pi1est(p_seq[n/2], p_seq)$est
    df$LSL[i] <- 1 - fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                 diagnostic.plot = FALSE)
    df$MGF[i] <- 1 - MGF_est(p_seq)
    df$JD[i] <- 1 - min(1, JD_est(p_seq, 100))
    df$LLF_CONVEST[i] <- 1 - limma::convest(p_seq)
    df$MR[i] <- MR_est(p_seq)
  }
  
  res <- rbind(apply(df, MARGIN = 2, FUN = mean),
               apply(df, MARGIN = 2, FUN = sd))
  res[1, ] <- res[1, ] - eps
  res <- rbind(res, sqrt(res[1, ]^2 + res[2, ]^2))
  rownames(res) <- c("BIAS", "SD", "RMSE")
  boxplot(df, ylab = expression(hat(pi)[1]))
  abline(h = eps)
  
  return((res))
}

```

The following code produces a LaTeX table with the simulation results

```{r sim_depend_test, eval = FALSE}

N <- 200
n_seq <- rep(100,6)
eps_seq <- c(0.05, 0.1, 0.1, 0.2, 0.2, 0.3)
mu_seq <- c( 3, 2, 3, 2, 3, 3)
set.seed(20)

pb <- txtProgressBar(max = length(n_seq))

table_list <- list()
for (i in 1:length(n_seq)) {
  table_list[[i]] <- round(dos_test_gaussian_depend(n_seq[i], eps_seq[i],
                                             mu_seq[i], N, 0.2) * n_seq[i], 1)
  rownames(table_list[[i]]) <- NULL
  
  setTxtProgressBar(pb, i)
}

close(pb)

combined_table <- do.call(rbind, table_list)
row_names <- as.data.frame(rep(c("BIAS", "SD", "RMSE"), length(n_seq)))
colnames(row_names) <- ""
combined_table <- cbind(row_names, combined_table)

add_rows <- list()
add_rows$pos <- as.list(3 * (1:length(n_seq) - 1))
mu_info <- paste("mu =", mu_seq)
eps_info <- paste("eps =", eps_seq)
add_rows$command <- paste("\\hline\n", "\\multicolumn{10}{c}{",
                          mu_info, ",", eps_info, "} \\\\\\hline ")
print(xtable(combined_table), add.to.row = add_rows, include.rownames = FALSE)

```

## DOS-Storey - FDR control

### Small Sample

In this section we recreate Figures 2, 3 and 4 from Blanchard, G., & Roquain, É. (2009). Adaptive false discovery rate control under independence and dependence. Journal of Machine Learning Research, 10, 2837–2871. http://jmlr.org/papers/v10/blanchard09a.html.
We include the adaptive procedures using Storey-based estimators and the DOS estimator of the proportion.

The following code produces 3 figures, showing the average estimated proportion value, FDR and power of different adaptive BH methods as a function of the true null proportion. 

```{r fdr control pi0, eval = FALSE}
n <- 100
N <- 1000
mu <- 3
pi0 <- 0.5 + 0.5 * (1:15-1) / 15
rho <- 0.2
alpha <- 0.05
arr <- array(data = rep(0, 3 * 7 * length(pi0)),
             dim = c(3, 7, length(pi0)),
             dimnames = list(c("pi0est", "FDR", "power"),
                             c("DOS-1", "DOS-1/2", "oracle", "ST-alpha", "ST-MED", "ST-1/2", "LSL"),
                             pi0))

div <- function(x, y) {
  ifelse(y == 0, 1, x / y)
}

for (j in 1:length(pi0)) {
  
  pi0est_dos1 <- pi0est_dos12 <- pi0est_alpha <- pi0est_12 <-  pi0est_lsl <-
    pi0est_med <- rep(0, N) 
  fdr_dos1 <- fdr_dos12 <- fdr_alpha <- fdr_oracle <- fdr_12 <- fdr_med <- fdr_lsl <-   rep(0, N)
  power_dos1 <- power_dos12 <- power_alpha <- power_oracle <- power_12 <- power_med <- power_lsl <-  rep(0, N)

  for (i in 1:N) {
    
    if (rho > 0) {
      eps <- sqrt(rho) * rnorm(1) + sqrt(1 - rho) * rnorm(n)
    } else {
      eps <- rnorm(n)
    }
    
    x <- eps + c(rep(0, floor(pi0[j] * n)), rep(mu, n - floor(n * pi0[j])))
    sig <- c(rep(0, floor(pi0[j] * n)), rep(1, n - floor(pi0[j] * n)))
    sig <- sig[order(1 - pnorm(x))]
    p_seq <- sort(1 - pnorm(x))
    
    pi0est_dos1[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1)$cp_loc], p_seq)$est
    pi0est_dos12[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1/2)$cp_loc], p_seq)$est
    pi0est_alpha[i] <- 1 - storey_pi1est(alpha, p_seq, mod = TRUE)$est
    pi0est_12[i] <- 1 - storey_pi1est(1/2, p_seq, mod = TRUE)$est
    pi0est_med[i] <- 1 - storey_pi1est(p_seq[n/2], p_seq, mod = TRUE)$est
    pi0est_lsl[i] <- fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                 diagnostic.plot = FALSE)
    
    
    abh_dos1 <- bh_adaptive(p_seq, pi0est_dos1[i], alpha, sig)
    fdr_dos1[i] <- abh_dos1$fdr
    power_dos1[i] <- abh_dos1$power
    
    abh_dos12 <- bh_adaptive(p_seq, pi0est_dos12[i], alpha, sig)
    fdr_dos12[i] <- abh_dos12$fdr
    power_dos12[i] <- abh_dos12$power
    
    abh_alpha <- bh_adaptive(p_seq, pi0est_alpha[i], alpha, sig)
    fdr_alpha[i] <- abh_alpha$fdr
    power_alpha[i] <- abh_alpha$power
    
    abh_oracle <- bh_adaptive(p_seq, pi0[j], alpha, sig)
    fdr_oracle[i] <- abh_oracle$fdr
    power_oracle[i] <- abh_oracle$power
    
    abh_12 <- bh_adaptive(p_seq, pi0est_12[i], alpha, sig)
    fdr_12[i] <- abh_12$fdr
    power_12[i] <- abh_12$power
    
    abh_med <- bh_adaptive(p_seq, pi0est_med[i], alpha, sig)
    fdr_med[i] <- abh_med$fdr
    power_med[i] <- abh_med$power
    
    abh_lsl <- bh_adaptive(p_seq, pi0est_lsl[i], alpha, sig)
    fdr_lsl[i] <- abh_lsl$fdr
    power_lsl[i] <- abh_lsl$power
  }
  
  arr["pi0est", "DOS-1", toString(pi0[j])] <- mean(pi0est_dos1)
  arr["pi0est", "DOS-1/2", toString(pi0[j])] <- mean(pi0est_dos12)
  arr["pi0est", "ST-alpha", toString(pi0[j])] <- mean(pi0est_alpha)
  arr["pi0est", "oracle", toString(pi0[j])] <- pi0[j]
  arr["pi0est", "ST-1/2", toString(pi0[j])] <- mean(pi0est_12)
  arr["pi0est", "ST-MED", toString(pi0[j])] <- mean(pi0est_med)
  arr["pi0est", "LSL", toString(pi0[j])] <- mean(pi0est_lsl)
  
  arr["FDR", "DOS-1", toString(pi0[j])] <- mean(fdr_dos1)
  arr["FDR", "DOS-1/2", toString(pi0[j])] <- mean(fdr_dos12)
  arr["FDR", "ST-alpha", toString(pi0[j])] <- mean(fdr_alpha)
  arr["FDR", "oracle", toString(pi0[j])] <- mean(fdr_oracle)  
  arr["FDR", "ST-1/2", toString(pi0[j])] <- mean(fdr_12) 
  arr["FDR", "ST-MED", toString(pi0[j])] <- mean(fdr_med) 
  arr["FDR", "LSL", toString(pi0[j])] <- mean(fdr_lsl) 
  
  arr["power", "DOS-1", toString(pi0[j])] <- mean(div(power_dos1, power_oracle))
  arr["power", "DOS-1/2", toString(pi0[j])] <- mean(div(power_dos12, power_oracle))
  arr["power", "ST-alpha", toString(pi0[j])] <- mean(div(power_alpha, power_oracle))
  arr["power", "oracle", toString(pi0[j])] <- mean(div(power_oracle, power_oracle))
  arr["power", "ST-1/2", toString(pi0[j])] <- mean(div(power_12, power_oracle))
  arr["power", "ST-MED", toString(pi0[j])] <- mean(div(power_med, power_oracle))
  arr["power", "LSL", toString(pi0[j])] <- mean(div(power_lsl, power_oracle))
}

mat_pi0 <- t(arr["pi0est", , ])
matplot(pi0, mat_pi0, type = "b", lwd = 1.5, pch = 1:7, col = seq_len(ncol(mat_pi0)), ylab = expression(hat(pi)[0]), xlab= expression(pi[0]), main = "Average proportion estimates")
legend("bottomright", lwd = 1.5,colnames(mat_pi0),  col = seq_len(ncol(mat_pi0)), cex = 0.8, pch=1:7)

mat_fdr <- t(arr["FDR", , ])
matplot(pi0, mat_fdr, type = "b", lwd = 1.5, pch = 1:7, col = seq_len(ncol(mat_pi0)), main = "FDR", ylab = "",  xlab= expression(pi[0]))
legend("topright", lwd= 1.5, colnames(mat_fdr), col = seq_len(ncol(mat_fdr)), cex = 0.8, pch = 1:7)
abline(h = alpha)


mat_power <- t(arr["power", , ])
matplot(pi0, mat_power, type = "b", lwd = 1.5, pch = 1:7, col = seq_len(ncol(mat_power)), main = "Relative power", ylab = "", xlab= expression(pi[0]))
legend("topleft", lwd = 1.5,colnames(mat_power), col = seq_len(ncol(mat_power)), cex = 0.8, pch = 1:7)

```

The following code produces 3 figures, showing the average proportion estimates, FDR and power of different adaptive BH methods as a function of the mean under the alternative.

```{r fdr control mu, eval = FALSE}
alpha <- 0.05
rho <- 0.5
mu <- seq(1, 5.5, by = 0.5)
pi0 <- 0.75

arr <- array(
  data = rep(0, 3 * 7 * length(mu)),
  dim = c(3, 7, length(mu)),
  dimnames = list(
    c("pi0est", "FDR", "power"),
    c("DOS-1", "DOS-1/2", "oracle", "ST-alpha", "ST-MED", "ST-1/2", "LSL"),
    mu
  )
)

N <- 10000

for (j in 1:length(mu)) {
  
  pi0est_dos1 <- pi0est_dos12 <- pi0est_alpha <- pi0est_12 <-  pi0est_lsl <-
    pi0est_med <- rep(0, N) 
  fdr_dos1 <- fdr_dos12 <- fdr_alpha <- fdr_oracle <- fdr_12 <- fdr_med <- fdr_lsl <-   rep(0, N)
  power_dos1 <- power_dos12 <- power_alpha <- power_oracle <- power_12 <- power_med <- power_lsl <-  rep(0, N)
  n <- 100
  
  for (i in 1:N) {
    if (rho > 0) {
      eps <- sqrt(rho) * rnorm(1) + sqrt(1 - rho) * rnorm(n)
    } else {
      eps <- rnorm(n)
    }
    
    x <- eps + c(rep(0, floor(pi0 * n)), rep(mu[j], n - floor(n * pi0)))
    sig <- c(rep(0, floor(pi0 * n)), rep(1, n - floor(pi0 * n)))
    sig <- sig[order(1 - pnorm(x))]
    p_seq <- sort(1 - pnorm(x))
    
    pi0est_dos1[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1)$cp_loc], p_seq)$est
    pi0est_dos12[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1/2)$cp_loc], p_seq)$est
    pi0est_alpha[i] <- 1 - storey_pi1est(alpha, p_seq, mod = TRUE)$est
    pi0est_12[i] <- 1 - storey_pi1est(1/2, p_seq, mod = TRUE)$est
    pi0est_med[i] <- 1 - storey_pi1est(p_seq[n/2], p_seq, mod = TRUE)$est
    pi0est_lsl[i] <- fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                 diagnostic.plot = FALSE)
    
    abh_dos1 <- bh_adaptive(p_seq, pi0est_dos1[i], alpha, sig)
    fdr_dos1[i] <- abh_dos1$fdr
    power_dos1[i] <- abh_dos1$power
    
    abh_dos12 <- bh_adaptive(p_seq, pi0est_dos12[i], alpha, sig)
    fdr_dos12[i] <- abh_dos12$fdr
    power_dos12[i] <- abh_dos12$power
    
    abh_alpha <- bh_adaptive(p_seq, pi0est_alpha[i], alpha, sig)
    fdr_alpha[i] <- abh_alpha$fdr
    power_alpha[i] <- abh_alpha$power
    
    abh_oracle <- bh_adaptive(p_seq, pi0, alpha, sig)
    fdr_oracle[i] <- abh_oracle$fdr
    power_oracle[i] <- abh_oracle$power
    
    abh_12 <- bh_adaptive(p_seq, pi0est_12[i], alpha, sig)
    fdr_12[i] <- abh_12$fdr
    power_12[i] <- abh_12$power
    
    abh_med <- bh_adaptive(p_seq, pi0est_med[i], alpha, sig)
    fdr_med[i] <- abh_med$fdr
    power_med[i] <- abh_med$power
        
    abh_lsl <- bh_adaptive(p_seq, pi0est_lsl[i], alpha, sig)
    fdr_lsl[i] <- abh_lsl$fdr
    power_lsl[i] <- abh_lsl$power
    
  }
  
  arr["pi0est", "DOS-1", toString(mu[j])] <- mean(pi0est_dos1)
  arr["pi0est", "DOS-1/2", toString(mu[j])] <- mean(pi0est_dos12)
  arr["pi0est", "ST-alpha", toString(mu[j])] <- mean(pi0est_alpha)
  arr["pi0est", "oracle", toString(mu[j])] <- pi0
  arr["pi0est", "ST-1/2", toString(mu[j])] <- mean(pi0est_12)
  arr["pi0est", "ST-MED", toString(mu[j])] <- mean(pi0est_med)
  arr["pi0est", "LSL", toString(mu[j])] <- mean(pi0est_lsl)
  
  arr["FDR", "DOS-1", toString(mu[j])] <- mean(fdr_dos1)
  arr["FDR", "DOS-1/2", toString(mu[j])] <- mean(fdr_dos12)
  arr["FDR", "ST-alpha", toString(mu[j])] <- mean(fdr_alpha)
  arr["FDR", "oracle", toString(mu[j])] <- mean(fdr_oracle)
  arr["FDR", "ST-1/2", toString(mu[j])] <- mean(fdr_12)
  arr["FDR", "ST-MED", toString(mu[j])] <- mean(fdr_med)
  arr["FDR", "LSL", toString(mu[j])] <- mean(fdr_lsl)
  
  arr["power", "DOS-1", toString(mu[j])] <- mean(div(power_dos1, power_oracle))
  arr["power", "DOS-1/2", toString(mu[j])] <- mean(div(power_dos12, power_oracle))
  arr["power", "ST-alpha", toString(mu[j])] <- mean(div(power_alpha, power_oracle))
  arr["power", "oracle", toString(mu[j])] <- mean(div(power_oracle, power_oracle))
  arr["power", "ST-1/2", toString(mu[j])] <- mean(div(power_12, power_oracle))
  arr["power", "ST-MED", toString(mu[j])] <- mean(div(power_med, power_oracle))
  arr["power", "LSL", toString(mu[j])] <- mean(div(power_lsl, power_oracle))
}

mat_pi0 <- t(arr["pi0est", , ])
matplot(mu, mat_pi0, type = "b", pch = 1:7, col = seq_len(ncol(mat_pi0)), xlab = expression(mu), ylab = expression(hat(pi)[0]), main = "Average proportion estimates")
legend("topright", colnames(mat_pi0), col = seq_len(ncol(mat_pi0)), cex = 0.8, pch= 1:7)

mat_fdr <- t(arr["FDR", , ])
matplot(mu, mat_fdr, type = "b", xlab = expression(mu), pch = 1:7, col = seq_len(ncol(mat_fdr)), main = "FDR", ylab = "")
legend("topleft", colnames(mat_fdr), col = seq_len(ncol(mat_fdr)), cex = 0.8, pch = 1:7)
abline(h = alpha)

mat_power <- t(arr["power", , ])
matplot(mu, mat_power, type = "b", xlab = expression(mu), pch = 1:7, col = seq_len(ncol(mat_power)), main = "Relative power", ylab = "")
legend("topright", colnames(mat_power), col = seq_len(ncol(mat_power)), cex = 0.8, pch = 1:7)
```

The following code produces 3 figures, showing the average proportion estimates, FDR and power of different adaptive BH methods as a function of the correlation coefficient $\rho$.

```{r fdr control rho, eval = FALSE}
rho <- (1:31 - 1) / 30
pi0 <- 0.75
mu <- 3
n <- 100
N <- 1000
arr <- array(
  data = rep(0, 3 * 7 * length(rho)),
  dim = c(3, 7, length(rho)),
  dimnames = list(
    c("pi0est", "FDR", "power"),
    c("DOS-1", "DOS-1/2", "oracle", "ST-alpha", "ST-MED", "ST-1/2", "LSL"),
    rho
  )
)

for (j in 1:length(rho)) {
  
  pi0est_dos1 <- pi0est_dos12 <- pi0est_alpha <- pi0est_12 <-  pi0est_lsl <-
    pi0est_med <- rep(0, N) 
  fdr_dos1 <- fdr_dos12 <- fdr_alpha <- fdr_oracle <- fdr_12 <- fdr_med <- fdr_lsl <-   rep(0, N)
  power_dos1 <- power_dos12 <- power_alpha <- power_oracle <- power_12 <- power_med <- power_lsl <-  rep(0, N)
  
  for (i in 1:N) {
    if (rho[j] > 0) {
      eps <- sqrt(rho[j]) * rnorm(1) + sqrt(1 - rho[j]) * rnorm(n)
    } else {
      eps <- rnorm(n)
    }
    
    x <- eps + c(rep(0, floor(pi0 * n)), rep(mu, n - floor(n * pi0)))
    sig <- c(rep(0, floor(pi0 * n)), rep(1, n - floor(pi0 * n)))
    sig <- sig[order(1 - pnorm(x))]
    p_seq <- sort(1 - pnorm(x))
    
    pi0est_dos1[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1)$cp_loc], p_seq)$est
    pi0est_dos12[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1/2)$cp_loc], p_seq)$est
    pi0est_alpha[i] <- 1 - storey_pi1est(alpha, p_seq, mod = TRUE)$est
    pi0est_12[i] <- 1 - storey_pi1est(1/2, p_seq, mod = TRUE)$est
    pi0est_med[i] <- 1 - storey_pi1est(p_seq[n/2], p_seq, mod = TRUE)$est
    pi0est_lsl[i] <- fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                 diagnostic.plot = FALSE)
    
    abh_dos1 <- bh_adaptive(p_seq, pi0est_dos1[i], alpha, sig)
    fdr_dos1[i] <- abh_dos1$fdr
    power_dos1[i] <- abh_dos1$power
    
    abh_dos12 <- bh_adaptive(p_seq, pi0est_dos12[i], alpha, sig)
    fdr_dos12[i] <- abh_dos12$fdr
    power_dos12[i] <- abh_dos12$power

    abh_alpha <- bh_adaptive(p_seq, pi0est_alpha[i], alpha, sig)
    fdr_alpha[i] <- abh_alpha$fdr
    power_alpha[i] <- abh_alpha$power
    
    abh_oracle <- bh_adaptive(p_seq, pi0, alpha, sig)
    fdr_oracle[i] <- abh_oracle$fdr
    power_oracle[i] <- abh_oracle$power
    
    abh_12 <- bh_adaptive(p_seq, pi0est_12[i], alpha, sig)
    fdr_12[i] <- abh_12$fdr
    power_12[i] <- abh_12$power
    
    abh_med <- bh_adaptive(p_seq, pi0est_med[i], alpha, sig)
    fdr_med[i] <- abh_med$fdr
    power_med[i] <- abh_med$power
    
    abh_lsl <- bh_adaptive(p_seq, pi0est_lsl[i], alpha, sig)
    fdr_lsl[i] <- abh_lsl$fdr
    power_lsl[i] <- abh_lsl$power
  }
  
  arr["pi0est", "DOS-1", toString(rho[j])] <- mean(pi0est_dos1)
  arr["pi0est", "DOS-1/2", toString(rho[j])] <- mean(pi0est_dos12)
  arr["pi0est", "ST-alpha", toString(rho[j])] <- mean(pi0est_alpha)
  arr["pi0est", "oracle", toString(rho[j])] <- pi0
  arr["pi0est", "ST-1/2", toString(rho[j])] <- mean(pi0est_12)
  arr["pi0est", "ST-MED", toString(rho[j])] <- mean(pi0est_med)
  arr["pi0est", "LSL", toString(rho[j])] <- mean(pi0est_lsl)
  
  arr["FDR", "DOS-1", toString(rho[j])] <- mean(fdr_dos1)
  arr["FDR", "DOS-1/2", toString(rho[j])] <- mean(fdr_dos12)
  arr["FDR", "ST-alpha", toString(rho[j])] <- mean(fdr_alpha)
  arr["FDR", "oracle", toString(rho[j])] <- mean(fdr_oracle)
  arr["FDR", "ST-1/2", toString(rho[j])] <- mean(fdr_12)
  arr["FDR", "ST-MED", toString(rho[j])] <- mean(fdr_med)
  arr["FDR", "LSL", toString(rho[j])] <- mean(fdr_lsl)
  
  arr["power", "DOS-1", toString(rho[j])] <- mean(div(power_dos1, power_oracle))
  arr["power", "DOS-1/2", toString(rho[j])] <- mean(div(power_dos12, power_oracle))
  arr["power", "ST-alpha", toString(rho[j])] <- mean(div(power_oracle, power_alpha))
  arr["power", "oracle", toString(rho[j])] <- mean(div(power_oracle, power_oracle))
  arr["power", "ST-1/2", toString(rho[j])] <- mean(div(power_oracle, power_12))
  arr["power", "ST-MED", toString(rho[j])] <- mean(div(power_oracle, power_med))
  arr["power", "LSL", toString(rho[j])] <- mean(div(power_oracle, power_lsl))
}

mat_pi0 <- t(arr["pi0est", , ])
matplot(rho, mat_pi0, type = "b", xlab = expression(rho), pch = 1:7, col = seq_len(ncol(mat_pi0)), ylab = expression(hat(pi)[0]), main = "Average proportion estimates")
legend("topright", colnames(mat_pi0), col = seq_len(ncol(mat_pi0)), cex = 0.8, pch = 1:7)

mat_fdr <- t(arr["FDR", , ])
matplot(rho, mat_fdr, type = "b", xlab = expression(rho), pch = 1:7, col = seq_len(ncol(mat_fdr)), main = "FDR", ylab = "")
legend("topleft", colnames(mat_fdr), col = seq_len(ncol(mat_fdr)), cex = 0.8, pch = 1:7)
abline(h = alpha)

mat_power <- t(arr["power", , ])
matplot(rho, mat_power, type = "b", xlab = expression(rho), pch = 1:7, col = seq_len(ncol(mat_power)), main = "Relative power", ylab = "")
legend("topleft", colnames(mat_power), col = seq_len(ncol(mat_power)), cex = 0.8, pch = 1:7)
```


### Large Sample

To include the $q$-value method, (that uses *STS* proportion estimator) which is the most popular method used for adaptive FDR control in applied literature, sample size needs to be larger (>200) and the method in general does not work for correlated $p$-values (in both cases the number of $p$-values close to 1 is not large enough for the proportion estimator to be computed)

The following code produces 3 figures, showing the average estimated proportion value, FDR and power of different adaptive BH methods as a function of the true null proportion. 

```{r fdr control smoother pi0 , eval = FALSE}
q_value_adaptive=function(p_seq, pi0, alpha, sig)
{
  n <- length(p_seq)
  res <- NULL
  q_est=sum(qvalue(p_seq,fdr.level=alpha,pi0=pi0)$significant)
  res$est <- q_est
  if (q_est == 0) {
    res$fdr <- 0
    res$power <- 0
  } else {
    res$fdr <- sum(1 - sig[1:q_est]) / q_est
    res$power <- sum(sig[1:q_est]) / sum(sig)
  }
  return(res)
}

n <- 500
N <- 1000 
mu <- 3
pi0 <- 0.5 + 0.5 * (1:15-1) / 15
rho <- 0
alpha <- 0.05
arr <- array(data = rep(0, 3 * 8 * length(pi0)),
             dim = c(3, 8, length(pi0)),
             dimnames = list(c("pi0est", "FDR", "power"),
                             c("STS", "LSL", "DOS-1", "DOS-1/2", "oracle", "ST-alpha", "ST-MED", "ST-1/2"),
                             pi0))

div <- function(x, y) {
  ifelse(y == 0, 1, x / y)
}

for (j in 1:length(pi0)) {
  
  pi0est_smoother <- pi0est_bh <- pi0est_dos1 <- pi0est_dos12 <- pi0est_alpha <- pi0est_12 <- pi0est_med <- rep(0, N)
  fdr_smoother <-  fdr_bh <- fdr_dos1 <- fdr_dos12 <- fdr_alpha <- fdr_oracle <- fdr_12 <- fdr_med <- rep(0, N)
  power_smoother <- power_bh <- power_dos1 <- power_dos12 <- power_alpha <- power_oracle <- power_12 <- power_med <- rep(0, N)
  stop_med <- stop_dos <- rep(0, N)
  
  for (i in 1:N) {
    
    if (rho > 0) {
      eps <- sqrt(rho) * rnorm(1) + sqrt(1 - rho) * rnorm(n)
    } else {
      eps <- rnorm(n)
    }
    
    x <- eps + c(rep(0, floor(pi0[j] * n)), rep(mu, n - floor(n * pi0[j])))
    sig <- c(rep(0, floor(pi0[j] * n)), rep(1, n - floor(pi0[j] * n)))
    sig <- sig[order(1 - pnorm(x))]
    p_seq <- sort(1 - pnorm(x))
    
    pi0est_dos1[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1)$cp_loc], p_seq)$est
    pi0est_dos12[i] <- 1 - storey_pi1est(p_seq[dos_fun(p_seq, alpha = 1/2)$cp_loc], p_seq)$est
    pi0est_alpha[i] <- 1 - storey_pi1est(alpha, p_seq, mod = TRUE)$est
    pi0est_12[i] <- 1 - storey_pi1est(1/2, p_seq, mod = TRUE)$est
    pi0est_med[i] <- 1 - storey_pi1est(p_seq[n/2], p_seq, mod = TRUE)$est
    pi0est_smoother[i] <- qvalue::pi0est(p_seq, pi0.method = "smoother")$pi0
    pi0est_bh[i] <- fdrtool::pval.estimate.eta0(p_seq, method = "adaptive",
                                                diagnostic.plot = FALSE)
    
    stop_med[i] <- p_seq[n/2]
    stop_dos[i] <- p_seq[dos_fun(p_seq)$cp_loc]
    
    abh_bh <- bh_adaptive(p_seq, pi0est_bh[i], alpha, sig)
    fdr_bh[i] <- abh_bh$fdr
    power_bh[i] <- abh_bh$power
    
    abh_smoother <- q_value_adaptive(p_seq, pi0est_smoother[i], alpha, sig)
    fdr_smoother[i] <- abh_smoother$fdr
    power_smoother[i] <- abh_smoother$power
    
    abh_dos1 <- bh_adaptive(p_seq, pi0est_dos1[i], alpha, sig)
    fdr_dos1[i] <- abh_dos1$fdr
    power_dos1[i] <- abh_dos1$power
    
    abh_dos12 <- bh_adaptive(p_seq, pi0est_dos12[i], alpha, sig)
    fdr_dos12[i] <- abh_dos12$fdr
    power_dos12[i] <- abh_dos12$power
    
    abh_alpha <- bh_adaptive(p_seq, pi0est_alpha[i], alpha, sig)
    fdr_alpha[i] <- abh_alpha$fdr
    power_alpha[i] <- abh_alpha$power
    
    abh_oracle <- bh_adaptive(p_seq, pi0[j], alpha, sig)
    fdr_oracle[i] <- abh_oracle$fdr
    power_oracle[i] <- abh_oracle$power
    
    abh_12 <- bh_adaptive(p_seq, pi0est_12[i], alpha, sig)
    fdr_12[i] <- abh_12$fdr
    power_12[i] <- abh_12$power
    
    abh_med <- bh_adaptive(p_seq, pi0est_med[i], alpha, sig)
    fdr_med[i] <- abh_med$fdr
    power_med[i] <- abh_med$power
  }
  
  arr["pi0est", "LSL", toString(pi0[j])] <- mean(pi0est_bh)
  arr["pi0est", "STS", toString(pi0[j])] <- mean(pi0est_smoother)
  arr["pi0est", "DOS-1", toString(pi0[j])] <- mean(pi0est_dos1)
  arr["pi0est", "DOS-1/2", toString(pi0[j])] <- mean(pi0est_dos12)
  arr["pi0est", "ST-alpha", toString(pi0[j])] <- mean(pi0est_alpha)
  arr["pi0est", "oracle", toString(pi0[j])] <- pi0[j]
  arr["pi0est", "ST-1/2", toString(pi0[j])] <- mean(pi0est_12)
  arr["pi0est", "ST-MED", toString(pi0[j])] <- mean(pi0est_med)
  
  arr["FDR", "LSL", toString(pi0[j])] <- mean(fdr_bh)
  arr["FDR", "STS", toString(pi0[j])] <- mean(fdr_smoother)
  arr["FDR", "DOS-1", toString(pi0[j])] <- mean(fdr_dos1)
  arr["FDR", "DOS-1/2", toString(pi0[j])] <- mean(fdr_dos12)
  arr["FDR", "ST-alpha", toString(pi0[j])] <- mean(fdr_alpha)
  arr["FDR", "oracle", toString(pi0[j])] <- mean(fdr_oracle)
  arr["FDR", "ST-1/2", toString(pi0[j])] <- mean(fdr_12)
  arr["FDR", "ST-MED", toString(pi0[j])] <- mean(fdr_med)
  
  arr["power", "LSL", toString(pi0[j])] <- mean(div(power_bh, power_oracle))
  arr["power", "STS", toString(pi0[j])] <- mean(div(power_smoother, power_oracle))
  arr["power", "DOS-1", toString(pi0[j])] <- mean(div(power_dos1, power_oracle))
  arr["power", "DOS-1/2", toString(pi0[j])] <- mean(div(power_dos12, power_oracle))
  arr["power", "ST-alpha", toString(pi0[j])] <- mean(div(power_alpha, power_oracle))
  arr["power", "oracle", toString(pi0[j])] <- mean(div(power_oracle, power_oracle))
  arr["power", "ST-1/2", toString(pi0[j])] <- mean(div(power_12, power_oracle))
  arr["power", "ST-MED", toString(pi0[j])] <- mean(div(power_med, power_oracle))
  
}

mat_pi0 <- t(arr["pi0est", , ])
matplot(pi0, mat_pi0, type = "b", pch = 1:8, col = seq_len(ncol(mat_pi0)), ylab = expression(hat(pi)[0]), xlab= expression(pi[0]), main = "Average proportion estimates")
legend("bottomright", colnames(mat_pi0), col = seq_len(ncol(mat_pi0)), cex = 0.8, pch=1:8)

mat_fdr <- t(arr["FDR",, ])
matplot(pi0, mat_fdr, type = "b", pch = 1:8, col = seq_len(ncol(mat_fdr)), main = "FDR", ylab = "",  xlab= expression(pi[0]))
legend("topleft", colnames(mat_fdr), col = seq_len(ncol(mat_fdr)), cex = 0.8, pch = 1:8)
abline(h = alpha)

mat_power <- t(arr["power", , ])
matplot(pi0, mat_power, type = "b", pch = 1:8, col = seq_len(ncol(mat_power)), main = "Relative power", ylab = "", xlab= expression(pi[0]))
legend("topleft", colnames(mat_power), col = seq_len(ncol(mat_power)), cex = 0.8, pch = 1:8)
abline(h=1)
```





## Numerical Results for the Ideal DOS Function

We load the data frame containing numerical results obtained in Mathematica. This dataframe contains the locations of the "true change-point", i.e. the maximum of the function $h_F^\alpha(t)$, for $\alpha = 1$, under the Gaussian model for various values of $\mu$ (columns) and $\varepsilon$ (rows).

```{r loading mathematica, eval = FALSE}
head(CP_loc_alpha05)

head(estimable_prop_sqrt)

head(CP_loc_alpha1)

head(estimable_prop_slope)
```


The next chunk plots the closeness of the estimable proportion under the Gaussian model, for various values of the parameters $\pi_1$ and $\mu$. The estimable false null proportion is the value towards which our proportion estimator converges asymptotically. It is defined as 
$$\tilde{\pi}_1^\alpha = \frac{\tilde{t}_\alpha - F^{-1}(\tilde{t}_\alpha) }{1 -  F^{-1}(\tilde{t}_\alpha)} \le \pi_1,$$ where $\tilde{t}_\alpha$ is the point of maximum of the function $h_F^\alpha$. The following plots explore how close that value is to the true proportion, by plotting $\frac{\tilde{\pi}_1^\alpha}{\pi_1}$ which is the percentage of the false null proportion possible to estimate. We consider this quantity for $\alpha = 1/2$ and $\alpha = 1$.

```{r estimable proportion alpha1, eval = FALSE}

estimable_prop_slope_sub <-  select(estimable_prop_slope, "2","3","4","5") 

true_props <- as.numeric(rownames(estimable_prop_slope_sub))

plot(as.numeric(rownames(estimable_prop_slope_sub)),
     estimable_prop_slope_sub[,1]/true_props,
     col = 2, pch= 18, xlab = "", ylab = "", ylim = c(0,1))
for(i in 2:ncol(estimable_prop_slope_sub))
{
  points(as.numeric(rownames(estimable_prop_slope_sub)),
     estimable_prop_slope_sub[,i]/true_props,
     col=i+1, pch=18, xlab="", ylab="")
}
title(ylab=expression(tilde(pi)[1]^alpha/pi[1]), line=2.5, cex.lab=1.2)
title(xlab=expression(pi[1]), line=2.5, cex.lab=1.2)
title(main = expression(paste("% of the proportion estimable, ", alpha == 1)))
legend("bottomright",
       legend = c(expression(mu[1]==2), expression(mu[1]==3),expression(mu[1]==4), expression(mu[1]==5)),
       col = 2:5,
       #lty=c(1,4),
       pch = 18,
       bty = "n",
       pt.cex = 1,
       cex = 1,
       text.col = "black",
       horiz = F ,
       inset = c(0.01, 0.01))

abline(h = 1)

```


```{r estimable proportion alpha05, eval = FALSE}


estimable_prop_sqrt_sub <-  select(estimable_prop_sqrt, "2","3","4","5") 

true_props <- as.numeric(rownames(estimable_prop_sqrt_sub))

plot(as.numeric(rownames(estimable_prop_sqrt_sub)),
     estimable_prop_sqrt_sub[,1]/true_props,
     col = 2, pch= 18, xlab = "", ylab = "", ylim = c(0,1))
for(i in 2:ncol(estimable_prop_sqrt_sub))
{
  points(as.numeric(rownames(estimable_prop_sqrt_sub)),
     estimable_prop_sqrt_sub[,i]/true_props,
     col=i+1, pch=18, xlab="", ylab="")
}
title(ylab=expression(tilde(pi)[1]^alpha/pi[1]), line=2.5, cex.lab=1.2)
title(xlab=expression(pi[1]), line=2.5, cex.lab=1.2)
title(main = expression(paste("% of the proportion estimable, ", alpha == 1/2)))
legend("bottomright",
       legend = c(expression(mu[1]==2), expression(mu[1]==3),expression(mu[1]==4), expression(mu[1]==5)),
       col = 2:5,
       #lty=c(1,4),
       pch = 18,
       bty = "n",
       pt.cex = 1,
       cex = 1,
       text.col = "black",
       horiz = F ,
       inset = c(0.01, 0.01))

```

```{r change point location alpha1, eval = FALSE}

cp_locs_sub <- select(CP_loc_alpha1, "2", "3", "4", "5")

true_props <- as.numeric(rownames(cp_locs_sub))

plot(as.numeric(rownames(cp_locs_sub)),
     cp_locs_sub[,1]/true_props,
     col = 2, pch= 18, xlab = "", ylab = "", ylim = c(0,1.5))
for(i in 2:ncol(cp_locs_sub))
{
  points(as.numeric(rownames(cp_locs_sub)),
     cp_locs_sub[,i]/true_props,
     col=i+1, pch=18, xlab="", ylab="")
}
title(ylab=expression(tilde(t)[alpha]/pi[1]), line=2.5, cex.lab=1.2)
title(xlab=expression(pi[1]), line=2.5, cex.lab=1.2)
title(main = expression(paste("Change-point location for ", alpha == 1)))
legend("bottomright",
       legend = c(expression(mu[1]==2), expression(mu[1]==3),expression(mu[1]==4), expression(mu[1]==5)),
       col = 2:5,
       #lty=c(1,4),
       pch = 18,
       bty = "n",
       pt.cex = 1,
       cex = 1,
       text.col = "black",
       horiz = F ,
       inset = c(0.01, 0.01))
abline(h=1)
```

```{r change point location alpha05, eval = FALSE}


cp_locs_sub <- select(CP_loc_alpha05, "2", "3", "4", "5")

true_props <- as.numeric(rownames(cp_locs_sub))

plot(as.numeric(rownames(cp_locs_sub)),
     cp_locs_sub[,1]/true_props,
     col = 2, pch= 18, xlab = "", ylab = "", ylim = c(0.9,2.3))
for(i in 2:ncol(cp_locs_sub))
{
  points(as.numeric(rownames(cp_locs_sub)),
     cp_locs_sub[,i]/true_props,
     col=i+1, pch=18, xlab="", ylab="")
}
title(ylab=expression(tilde(t)[alpha]/pi[1]), line=2.5, cex.lab=1.2)
title(xlab=expression(pi[1]), line=2.5, cex.lab=1.2)
title(main = expression(paste("Change-point location for ", alpha == 0.5)))
legend("topleft",
       legend = c(expression(mu[1]==2), expression(mu[1]==3),expression(mu[1]==4), expression(mu[1]==5)),
       col = 2:5,
       #lty=c(1,4),
       pch = 18,
       bty = "n",
       pt.cex = 1,
       cex = 1,
       text.col = "black",
       horiz = F ,
       inset = c(0.01, 0.01))

abline(h=1)
```

## Dependency on the Number of Excluded Values

The following function is used for checking the dependence of the DOS-Storey estimator on the proportion of excluded $p$-values in the Gaussian case. To have the asymptotic results hold for $n\to \infty$, sufficient conditions on the proportion of excluded values $c_n$ are given in the main paper. The simulations show that the estimator is not sensitive to $c_n$, and no values need to be excluded from the beginning.

```{r dependency on cn, eval = FALSE}

cp_exc <- function(n,eps,mu,N,exc_seq)
{
  m <- length(exc_seq)
  exc_cp <- rep(0,m)
  exc_est <- rep(0, m)
  count_res <- rep(0,m)
  
  for(i in 1:N)
  {
    x=c(rnorm(floor(eps*n),mu),rnorm(n-floor(n*eps)))
    p_seq=sort(1-pnorm(x))

    temp_noexc <- dos_fun(p_seq, alpha = 1, exc = 0)$cp_loc
    
    for(j in 1:m)
    {
      temp_exc <- dos_fun(p_seq, alpha = 1, exc = exc_seq[j])$cp_loc
      exc_cp[j] <- exc_cp[j] + temp_exc
      exc_est[j] <- exc_est[j] +  storey_pi1est(p_seq[temp_exc], p_seq)$est
      
      if(temp_exc != temp_noexc)
    {
      count_res[j] = count_res[j] + 1
    }
    }
    
  }
  
    exc_cp <- exc_cp/N/n
    exc_est <- exc_est/N
    
    ret = NULL
    ret$count = count_res
    ret$cp_locs = exc_cp
    ret$prop_est <- exc_est
    
    return(ret)

}

```

For given parameter values of the Gaussian model, the following code plots the estimated change-point location and proportion as a function of $c$ ($c_n$). We see that only larger $c \approx \pi_1$ start affecting the estimates.


```{r test, eval = FALSE}
mu <- 2
eps <- 0.05
N <- 1000
n_size <- c(100,1000,10000, 100000)
exc_seq <- seq(0,eps + 0.05, length.out = 10)

par(mar = c(4,5,2,1)) 
plot(1, 
     type="n", 
     xlab=expression(c), 
     ylab=expression(hat(k)[1](c)/n), 
     xlim=c(0, eps), 
     ylim=c(0, 2*eps))
abline(h = CP_loc_alpha1$"2"[eps*100], col = "grey")
for(k in 1:length(n_size))
{
  res <- cp_exc(n_size[k],eps,mu,N,exc_seq = exc_seq)
  lines(exc_seq, res$cp_locs, lty = k)
}
legend("topleft", legend = n_size, lty = c(1,2,3,4), cex = 0.8)

par(mar = c(4,5,2,1)) 
plot(1, 
     type="n", 
     xlab=expression(c), 
     ylab=expression({hat(pi)^{1}}[1](c)), 
     xlim=c(0, eps), 
     ylim=c(0, 2*eps))
#abline(h = eps, col = "grey")
abline(h = estimable_prop_slope$"2"[eps*100], col = "grey")
for(k in 1:length(n_size))
{
  res <- cp_exc(n_size[k],eps,mu,N,exc_seq = exc_seq)
  lines(exc_seq, res$prop_est, lty = k)
}
legend("topright", legend = n_size, lty = c(1,2,3,4), cex = 0.8)



```

## Comparing With the Other Change-Point Methods

The following code performs the simulation and produces a LaTeX table (requires \texttt{xtable} package) with simulation results comparing the DOS-Storey method to the two other change-point-based methods for proportion estimation proposed in the literature: 

* Hwang, Y.-T., Kuo, H.-C., Wang, C.-C., & Lee, M. F. (2014). Estimating the number of true null hypotheses in multiple hypothesis testing. Statistics and Computing, 24(3), 399–416. https://doi.org/10.1007/s11222-013-9377-5

* Turkheimer, F. E., Smith, C. B., & Schmidt, K. (2001). Estimation of the number of “true” null hypotheses in multivariate analysis of neuroimaging data. NeuroImage, 13(5), 920–930. https://doi.org/10.1006/nimg.2001.0764

```{r cp compare fun, eval = FALSE}
test_cp_methods <- function(n,eps,mu,N)
{
  mat <- matrix(0, N, 4)
  colnames(mat)=c("DOS1", "DOS05", "HWANG", "TURK")
  
  df <- data.frame(mat)

  for (i in 1:N) {
    p_seq <- sort(sim_pval(n, 0, mu, eps, 0))
    
    df$DOS1[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1)$cp_loc], p_seq)$est
    df$DOS05[i] <- storey_pi1est(p_seq[dos_fun(p_seq,
                                              alpha = 1/2)$cp_loc], p_seq)$est

    df$HWANG[i] <- 1 - Hwang_est(p_seq)
    df$TURK[i] <- 1 - turkheimer_est(p_seq, alpha = 0.05)
    
  }
  
  res <- rbind(apply(df, MARGIN = 2, FUN = mean),
               apply(df, MARGIN = 2, FUN = sd))
  res[1, ] <- res[1, ] - eps
  res <- rbind(res, sqrt(res[1, ]^2 + res[2, ]^2))
  rownames(res) <- c("BIAS", "SD", "RMSE")
  #boxplot(df, ylab = expression(hat(pi)[1]))
  #abline(h = eps)
  
  return((res))
}

```


```{r cp compare res, eval = FALSE}
set.seed(10)
N <- 1000
n_seq <- rep(1000, 8)
eps_seq <- c(0.01, 0.03, 0.05, 0.1, 0.1, 0.2, 0.2, 0.3)
mu_seq <- c(3.5, 3.5, 3, 2, 3, 2, 3, 3)

table_list <- list()
for (i in 1:length(n_seq)) {
  table_list[[i]] <- round(test_cp_methods(n_seq[i], eps_seq[i],
                                             mu_seq[i], N) * n_seq[i], 1)
  rownames(table_list[[i]]) <- NULL
}

combined_table <- do.call(rbind, table_list)
row_names <- as.data.frame(rep(c("BIAS", "SD", "RMSE"), length(n_seq)))
colnames(row_names) <- ""
combined_table <- cbind(row_names, combined_table)

add_rows <- list()
add_rows$pos <- as.list(3 * (1:length(n_seq) - 1))
mu_info <- paste("mu =", mu_seq)
eps_info <- paste("eps =", eps_seq)
add_rows$command <- paste("\\hline\n", "\\multicolumn{4}{c}{",
                          mu_info, ",", eps_info, "} \\\\\\hline ")
print(xtable(combined_table), add.to.row = add_rows, include.rownames = FALSE)
```

## A Counterexample Illustrating Violations of Assumption A2 on $h$

```{r counterexample, eval = FALSE}
# Define a piecewise linear function given the
# breakpoint sequence t and the slopes sequence a
multi_mix_quantile <- function(x, a, t) {
  t <- c(0, t)
  a <- c(a, (1 - sum(a * diff(t))) / (1 - t[length(t)]))
  t <- c(t, 1)
  rez <- rep(0, length(x))
  
  for (j in 1:length(x)) {
    cdf <- 0
    
    if (x[j] == 0) {
      rez[j] <- 0
    } else {
      int_id <- min(which(x[j] <= t)) - 1
      
      if (int_id == 1) {
        rez[j] <- a[1] * x[j]
      } else {
        rez[j] <- sum(a[1:(int_id - 1)] * (diff(t)[1:(int_id - 1)])) + a[int_id] * (x[j] - t[int_id])
      }
    }
  }
  
  return(rez)
}

# The corresponding DOS sequence for the piecewise linear function
# defined by the breakpoint sequence t and the slopes sequence a
h_multi <- function(x, a, t) (multi_mix_quantile(2 * x, a, t) - 2 * multi_mix_quantile(x, a, t)) / x

a <- c(0.1, 0.2, 0.4, 0.9)
t <- c(0.1, 0.2, 0.3, 0.4)
t1 <- c(0, t)
(1 - sum(a * diff(t1))) / (1 - t1[length(t1)])
a1 <- c(a, (1 - sum(a * diff(t1))) / (1 - t1[length(t1)]))

curve(multi_mix_quantile(x, a = a, t = t), from = 0, to = 1, ylab = "Q(t)", xlab = "t")
curve(h_multi(x, a = a, t = t), from = 0, to = 1/2, ylab = "h(t)", xlab = "t")
cps <- sort(unique(c(t, t/2)))  # The change-points in the h function
#abline(v = cps)

```

